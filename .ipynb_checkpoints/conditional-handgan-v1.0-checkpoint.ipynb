{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6160d8",
   "metadata": {},
   "source": [
    "### Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9b9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU,Conv2DTranspose,Embedding,Input,Dense,Flatten,Conv2D,Concatenate,MaxPooling2D,Reshape\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b4983",
   "metadata": {},
   "source": [
    "### Ön Tanımlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1762654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (160,160,3)\n",
    "batch_size = 15\n",
    "latent_dim = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dcb164",
   "metadata": {},
   "source": [
    "### Veri Seti ve Ön İşlemler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15757c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"trashsock/hands-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecd06d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels_tr = {\n",
    "    0 : \"kapalı yumruk\",\n",
    "    1 : \"parmak çevreler\",\n",
    "    2 : \"parmak semboller\",\n",
    "    3 : \"yarım parmak bükme\",\n",
    "    4 : \"açık avuç\",\n",
    "    5 : \"yarım açık yumruk\",\n",
    "    6 : \"yarım açık avuç\",\n",
    "    7 : \"tek parmak bükme\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b85d7",
   "metadata": {},
   "source": [
    "Etiketleri tokenize etmek için etiketlerde geçen sözcükleri\n",
    "saymalıyız. Bu yüzden önce tüm etiketleri tek cümlede \n",
    "topluyoruz. Sonra Counter sınıfı ile hepsini saydırıyoruz.\n",
    "Counter sınıfı \"\" boş stringide en sonda kelime olarak eklediği için onu sileceğiz.\n",
    "\n",
    "Bu işlem etiketleri bir dict (sözlük) yapısından aldığımız için gerekli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d87dc67",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm labellerin birleştirilmiş hali \n",
      " kapalı yumruk parmak çevreler parmak semboller yarım parmak bükme açık avuç yarım açık yumruk yarım açık avuç tek parmak bükme  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "collected = \"\"\n",
    "for i in dataset_labels_tr.values():\n",
    "    collected+=f\"{i} \"\n",
    "print(\"Tüm labellerin birleştirilmiş hali \\n\",collected,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20e45c09",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adet: 1 kelime: kapalı \n",
      "adet: 2 kelime: yumruk \n",
      "adet: 4 kelime: parmak \n",
      "adet: 1 kelime: çevreler \n",
      "adet: 1 kelime: semboller \n",
      "adet: 3 kelime: yarım \n",
      "adet: 2 kelime: bükme \n",
      "adet: 3 kelime: açık \n",
      "adet: 2 kelime: avuç \n",
      "adet: 1 kelime: tek \n",
      "adet: 1 kelime:  \n"
     ]
    }
   ],
   "source": [
    "word_dictionary_list = []\n",
    "for word, number in Counter(collected.split(\" \")).items():\n",
    "    word_dictionary_list.append(word)\n",
    "    print(f\"adet: {number} kelime: {word} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a349ee4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sözlük\n",
      " ['kapalı', 'yumruk', 'parmak', 'çevreler', 'semboller', 'yarım', 'bükme', 'açık', 'avuç', 'tek']\n"
     ]
    }
   ],
   "source": [
    "word_dictionary_list.remove(\"\")\n",
    "print(\"Sözlük\\n\",word_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8811485",
   "metadata": {},
   "source": [
    "Oluşturduğumuz sözlükteki her etiket için bir sayı atamamız gerekiyor. Bu sebeple LabelEncoder sınıfını kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae71a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "498bc464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodlanmış etiketler:\n",
      " {'kapalı': 3, 'yumruk': 8, 'parmak': 4, 'çevreler': 9, 'semboller': 5, 'yarım': 7, 'bükme': 2, 'açık': 1, 'avuç': 0, 'tek': 6}\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoded = encoder.fit_transform(word_dictionary)\n",
    "word_dictionary_encoded = {}\n",
    "\n",
    "for idx in range(len(encoded)):\n",
    "    word_dictionary_encoded[word_dictionary_list[idx]] = encoded[idx]\n",
    "print(\"Kodlanmış etiketler:\\n\",word_dictionary_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb6ac9",
   "metadata": {},
   "source": [
    "Token haline getirdiğimiz kelimeler ile verisetindeki sınıf etiketlerimizi tekrardan kodlamamız gerekiyor. Çünkü bu sınıf etiketlerini kodlanmış şekilde eğitimde kullanacağız.\n",
    "Vektörlerimiz 3 uzunluğunda olacak. Eğer 3'den az ise 0 ekleyerek padding işlemi yapacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e960ef5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([3, 8, 0], dtype=int64))\n",
      "(1, array([4, 9, 0], dtype=int64))\n",
      "(2, array([4, 5, 0], dtype=int64))\n",
      "(3, array([7, 4, 2], dtype=int64))\n",
      "(4, array([1, 0, 0], dtype=int64))\n",
      "(5, array([7, 1, 8], dtype=int64))\n",
      "(6, array([7, 1, 0], dtype=int64))\n",
      "(7, array([6, 4, 2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "def convert_label_to_vector():\n",
    "    label_vectors = {}\n",
    "    for key ,value in dataset_labels_tr.items():\n",
    "        words = value.split(\" \")\n",
    "        row_encodes = []\n",
    "        for word in words:\n",
    "            row_encodes.append(word_dictionary_encoded[word])\n",
    "        \n",
    "        if(len(row_encodes) != 3):\n",
    "            row_encodes.append(0)\n",
    "            \n",
    "        label_vectors[key] = np.array(row_encodes)\n",
    "    \n",
    "    return label_vectors\n",
    "\n",
    "labels_vectorized_dict = convert_label_to_vector()\n",
    "for i in labels_vectorized_dict.items():print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a343d",
   "metadata": {},
   "source": [
    "Yaptığımız vektörizasyon işlemini veri setine uyguluyoruz.\n",
    "Ayrıca resimleride modele uygun hale getiriyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8fcea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = np.array(image)\n",
    "    image = cv2.resize(image,(inp_size[0],inp_size[1]))\n",
    "    image = (image/255)\n",
    "    return image\n",
    "\n",
    "def preprocess_label(label):\n",
    "    return np.array(tokenized_labels[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f7879c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():   \n",
    "    train_images = map(preprocess_image,dataset[\"train\"][\"image\"])\n",
    "    train_labels = map(preprocess_label,dataset[\"train\"][\"label\"])\n",
    "    return [train_images,train_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c4af8",
   "metadata": {},
   "source": [
    "Model eğitimi sırasında kullanacağımız gerçek ve sahte verileri üretmemiz gerekiyor. Aşağıda bu işlemi yapıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "371db274",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_number = np.random.randint\n",
    "get_random_vector = np.random.randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39ec759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(real_images,real_labels,n_samples):\n",
    "    \"\"\"\n",
    "    [n_samples] : Üretilecek veri boyutu\n",
    "    \"\"\"\n",
    "    \n",
    "    # sample sayısı kadar 0 ile verisetinin uzunluğu arasında rastgele sayı üret\n",
    "    ix = get_random_number(0,real_images.shape[0],n_samples)\n",
    "    images , labels = real_images[ix], real_labels[ix]\n",
    "    \n",
    "    # Gerçek olduğu etiketi\n",
    "    y = np.ones((n_samples,1))\n",
    "    \n",
    "    return [images,labels],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5bdfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_seeds(latent_dim, n_samples ,n_classes):\n",
    "    latent_seeds = get_random_vector(latent_dim * n_samples)\n",
    "    latent_seeds = np.reshape(latent_seeds,(n_samples,latent_dim))\n",
    "    \n",
    "    labels = get_random_number(0,n_classes,3*n_samples)\n",
    "    labels = np.reshape(labels,(n_samples,3))\n",
    "    \n",
    "    return [latent_seed,labels]\n",
    "\n",
    "def generate_fake_samples(generator,latent_dim,n_samples,n_classes):\n",
    "    fake_image , fake_label = generate_latent_seeds(latent_dim,n_samples,n_classes)\n",
    "    predicted_images = generator.predict([fake_image,fake_label])\n",
    "    \n",
    "    y = zeros((n_samples,1))\n",
    "    \n",
    "    return [predicted_images,fake_label],y    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92affdba",
   "metadata": {},
   "source": [
    "### Eğitim İşlemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f27c5",
   "metadata": {},
   "source": [
    "<p>Her bir döngü için aslında modeli 3 kez eğiteceğiz ama farklı şekillerde.</p>\n",
    "<p>Önce ayırıcı ağı gerçek resim ve etiket girdileri ile [1] elde etmesi için eğiteceğiz</p>\n",
    "<p>Ardından ayırıcı ağı sahte resim ve etiket girdileri ile [0] elde etmesi için eğiteceğiz,</p>\n",
    "<p>Sonrasında çekişme modelinin tümünü rastgeler resim ve etiket tohumlarıyla [1] elde etmesi için eğiteceğiz.</p>\n",
    "<p>Son yapılan işlemde üretici ağın daha gerçek görüntüler oluşturmasını amaçlıyoruz. Ve bu gerçekliğin ne ölçüde olduğunu anlamak için aslında yine ayırıcı ağdan faydalanıyoruz.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images , real_labels = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_gen,model_disc,model_gan,real_images,real_labels,latent_dim,epochs,batch_size,n_classes):\n",
    "    \n",
    "    batch_per_epoch = dataset.shape[0] / batch_size\n",
    "    half_batch = int(batch_size / 2)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "            [real_xi, real_xl],real_y = generate_real_samples(real_images,real_labels,half_batch)\n",
    "            d_loss1 , _ = model_disc.train_on_batch([real_xi,real_xl],real_y)\n",
    "            \n",
    "            [fake_xi,fake,xl],fake_y = generate_fake_samples(model_gen,latent_dim,n_half_batch,n_classes)\n",
    "            d_loss2 , _ = model_disc.train_on_batch([fake_xi,fake,xl],fake_y)\n",
    "            \n",
    "            [predicted_xi, xl] = generate_latent_seeds(latent_dim,n_samples,n_classes)\n",
    "            gan_y = np.ones((batch_size,1))\n",
    "            \n",
    "            g_loss = model_gan.train_on_batch([predicted_xi, xl], gan_y)\n",
    "            \n",
    "            print(f\"{i+1} {j+1} {d_loss1} {d_loss2} {g_loss}\")\n",
    "        model_gen.save(f'./models/generator_model_{i+1}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770935",
   "metadata": {},
   "source": [
    "### Ayırıcı Ağ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "265a9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(in_shape):\n",
    "    inp_label = Input((3,))\n",
    "    embedding = Embedding(1,50,input_length=3)(inp_label)\n",
    "    d1 = Dense(in_shape[0]*in_shape[1])(embedding)\n",
    "    reshape1 = Reshape(in_shape)(d1)\n",
    "    \n",
    "    inp_image = Input(in_shape)\n",
    "    concat1 = Concatenate()([reshape1,inp_image])\n",
    "    \n",
    "    conv1 = Conv2D(128,(3,3),strides=(2,2))(concat1)\n",
    "    conv2 = Conv2D(128,(3,3),strides=(1,1))(conv1)\n",
    "    conv3 = Conv2D(128,(5,5),strides=(2,2))(conv2)\n",
    "    conv4 = Conv2D(128,(3,3),strides=(2,2))(conv3)\n",
    "    conv5 = Conv2D(128,(3,3),strides=(2,2))(conv4)\n",
    "    \n",
    "    flat1 = Flatten()(conv5)\n",
    "    dense_output = Dense(1)(flat1)\n",
    "    \n",
    "    opt = Adam(learning_rate=0.0002,beta_1=0.5)\n",
    "    model = Model([inp_label,inp_image],dense_output)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77202d5e",
   "metadata": {},
   "source": [
    "### Üretici Ağ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f85b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim=150):\n",
    "    inp_label = Input((3,))\n",
    "    embedding = Embedding(1,50,input_length=3)(inp_label)\n",
    "    flat1 = Flatten()(embedding)\n",
    "    \n",
    "    inp_image_latent = Input((latent_dim))\n",
    "    concated = Concatenate()([flat1,inp_image_latent])\n",
    "    d1 = Dense(10*10*20)(concated)\n",
    "    reshape1 = Reshape((10,10,20))(d1)\n",
    "    \n",
    "    conv1 = Conv2DTranspose(72,(3,3),strides=(2,2),padding='same')(reshape1)\n",
    "    conv1 = LeakyReLU(alpha=0.2)(conv1)\n",
    "    conv2 = Conv2DTranspose(72,(5,5),strides=(2,2),padding='same')(conv1)\n",
    "    conv2 = LeakyReLU(alpha=0.2)(conv2)\n",
    "    conv3 = Conv2DTranspose(72,(3,3),strides=(2,2),padding='same')(conv2)\n",
    "    conv3 = LeakyReLU(alpha=0.2)(conv3)\n",
    "    conv4 = Conv2DTranspose(3,(3,3),strides=(2,2),padding='same')(conv3)\n",
    "    conv4 = LeakyReLU(alpha=0.2)(conv4)\n",
    "    \n",
    "    model = Model([inp_label,inp_image_latent],conv4)\n",
    "    model.compile(\"rmsprop\",\"mse\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a04084",
   "metadata": {},
   "source": [
    "### Çekişme Modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f455bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(model_gen,model_disc):\n",
    "    model_disc.trainable = False\n",
    "    gen_label,  gen_noise= model_gen.input\n",
    "    gen_output = model_gen.output\n",
    "    gan_output = model_disc([gen_label,gen_output])\n",
    "    \n",
    "    model = Model([gen_label,gen_noise], gan_output)\n",
    "    \n",
    "    opt = Adam(lr=0.0002,beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=opt)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
